{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bank.csv dataset\n",
    "#Ensembling Technique \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2343</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1270</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2476</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  balance  housing  loan  contact  \\\n",
       "0   59    0        1          1        0     2343        1     0        2   \n",
       "1   56    0        1          1        0       45        0     0        2   \n",
       "2   41    9        1          1        0     1270        1     0        2   \n",
       "3   55    7        1          1        0     2476        1     0        2   \n",
       "4   54    0        1          2        0      184        0     0        2   \n",
       "\n",
       "   day  month  duration  campaign  pdays  previous  poutcome  deposit  \n",
       "0    5      8      1042         1     -1         0         3        1  \n",
       "1    5      8      1467         1     -1         0         3        1  \n",
       "2    5      8      1389         1     -1         0         3        1  \n",
       "3    5      8       579         1     -1         0         3        1  \n",
       "4    5      8       673         2     -1         0         3        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To load dataset bank.csv\n",
    "df=pd.read_csv(\"bank.csv\")\n",
    "#to display first 5 records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "job          0\n",
       "marital      0\n",
       "education    0\n",
       "default      0\n",
       "balance      0\n",
       "housing      0\n",
       "loan         0\n",
       "contact      0\n",
       "day          0\n",
       "month        0\n",
       "duration     0\n",
       "campaign     0\n",
       "pdays        0\n",
       "previous     0\n",
       "poutcome     0\n",
       "deposit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Bank has launch marketing campaning which is based on telephone call and each row actually\n",
    "representing an information about each telephone call.\n",
    "Now we predict either customer will subscribe the deposit or not, basis of this information'''\n",
    "\n",
    "#first, check null values in given dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11162 entries, 0 to 11161\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   age        11162 non-null  int64\n",
      " 1   job        11162 non-null  int64\n",
      " 2   marital    11162 non-null  int64\n",
      " 3   education  11162 non-null  int64\n",
      " 4   default    11162 non-null  int64\n",
      " 5   balance    11162 non-null  int64\n",
      " 6   housing    11162 non-null  int64\n",
      " 7   loan       11162 non-null  int64\n",
      " 8   contact    11162 non-null  int64\n",
      " 9   day        11162 non-null  int64\n",
      " 10  month      11162 non-null  int64\n",
      " 11  duration   11162 non-null  int64\n",
      " 12  campaign   11162 non-null  int64\n",
      " 13  pdays      11162 non-null  int64\n",
      " 14  previous   11162 non-null  int64\n",
      " 15  poutcome   11162 non-null  int64\n",
      " 16  deposit    11162 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()#datatype check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select Input X and output Y  from given dataset df\n",
    "X=df.drop(\"deposit\",axis=1) #input features\n",
    "Y=df[\"deposit\"]#output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined function\n",
    "def create_model(model):\n",
    "    model.fit(X_train,Y_train)  #train the model\n",
    "    Y_pred=model.predict(X_test) #Test the model\n",
    "    print(classification_report(Y_test,Y_pred))\n",
    "    print(\"Confusion Matrix \")\n",
    "    print(confusion_matrix(Y_test,Y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we take 3 types of classification algorithm to train the dataset\n",
    "#1. Logistic regression  2. Decision tree(Gini index) 3. DecisionTree(Entropy) \n",
    "#call Logistic regression class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#call decisiontreeclassifier class\n",
    "from sklearn.tree import DecisionTreeClassifier  #DecisionTreeClassifier inbuilt class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "#create object of DecisionTreeClassifier with gini index\n",
    "dt1=DecisionTreeClassifier() #befault gini index\n",
    "#create object of DecisionTreeClassifier with entropy\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A List consists of multiple tuples and each tuples the first argument has to be a string \\nthat is a name of the model and second argument has to be a object of model(algorithm)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a model list\n",
    "model_list=[(\"Logistic\",lr),(\"DecisionTree-GiniIndex\",dt1),(\"DecisionTree-Entropy\",dt2)]\n",
    "#here model_list is a user defined list object\n",
    "'''A List consists of multiple tuples and each tuples the first argument has to be a string \n",
    "that is a name of the model and second argument has to be a object of model(algorithm)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we need Naive aggregation\n",
    "#we importing class\n",
    "from sklearn.ensemble import VotingClassifier  #VotingClassifier inbuilt class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of VotingClassifier  class\n",
    "vc1=VotingClassifier(estimators=model_list) #here estimators inbuilt parameter of VotingClassifier  \n",
    "#class , here pass the model_list in this parameter \n",
    "#budefault mension hard voting if no define any parameter for hard voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      1760\n",
      "           1       0.81      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.82      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1451  309]\n",
      " [ 302 1287]]\n"
     ]
    }
   ],
   "source": [
    "#Let call function create_model\n",
    "vc1=create_model(vc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft voting \n",
    "#create object of VotingClassifier  class\n",
    "vc2=VotingClassifier(estimators=model_list,voting=\"soft\")#bydefault voting=\"hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.81      1589\n",
      "\n",
      "    accuracy                           0.82      3349\n",
      "   macro avg       0.81      0.82      0.82      3349\n",
      "weighted avg       0.82      0.82      0.82      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1444  316]\n",
      " [ 302 1287]]\n"
     ]
    }
   ],
   "source": [
    "#Let call function create_model\n",
    "vc2=create_model(vc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Difference between Bagging and pasting classifier : - \\nIn bagging classifier ,  the model is train with different samples with replacement .\\nwhile other hand  in pasting , the model is train with different samples without replacement'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Bootstrapping\n",
    "#A. Bagging  B. Pasting   C. Random forest\n",
    "\n",
    "'''Difference between Bagging and pasting classifier : - \n",
    "In bagging classifier ,  the model is train with different samples with replacement .\n",
    "while other hand  in pasting , the model is train with different samples without replacement'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Difference between BNaive aggregation and bootstraping aggregation : -\\nIn naive aggregation , we choose a different types of models(algorithms) or you can say different\\ntypes of algorithms and \\nIn bootstrapping aggregation , We choose only one type of algorithm and each of those algorithm \\na train with different samples '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Difference between BNaive aggregation and bootstraping aggregation : -\n",
    "In naive aggregation , we choose a different types of models(algorithms) or you can say different\n",
    "types of algorithms and \n",
    "In bootstrapping aggregation , We choose only one type of algorithm and each of those algorithm \n",
    "a train with different samples '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Bagging : call class BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of BaggingClassifier inbuilt class\n",
    "bc=BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=10,random_state=1)\n",
    "#first pass parameter in the function : - we need to pass what type of algorithm be need to use ,suppose \n",
    "#we choose to use Logistic regression algo.\n",
    "#second parameter : - how many algorithm means select n_estimators=10 means we want to \n",
    "#10 logistic regression ,\n",
    "#third parameter : There are 10 logistic regression algo. and each of them will be train on 10\n",
    "#samples may be 100 (10*10=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1760\n",
      "           1       0.74      0.73      0.73      1589\n",
      "\n",
      "    accuracy                           0.75      3349\n",
      "   macro avg       0.75      0.75      0.75      3349\n",
      "weighted avg       0.75      0.75      0.75      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1359  401]\n",
      " [ 434 1155]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "bc=create_model(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasting \n",
    "#create object of BaggingClassifier inbuilt class\n",
    "bc1=BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=10,random_state=1,\n",
    "                      bootstrap=False) #by default bootstrap parameter=True means use Bagging\n",
    "#if pass value in parameter bootstrap=False then use pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1760\n",
      "           1       0.74      0.73      0.73      1589\n",
      "\n",
      "    accuracy                           0.75      3349\n",
      "   macro avg       0.75      0.75      0.75      3349\n",
      "weighted avg       0.75      0.75      0.75      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1359  401]\n",
      " [ 434 1155]]\n"
     ]
    }
   ],
   "source": [
    "#call function \n",
    "bc1=create_model(bc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same score are obtained  in bagging and pasting  \n",
    "#but better score obtained from voting as compare to bagging and pasting in this dataset bank.csv\n",
    "#in hard as soft voting : - recall : 81% means .81 which is good score as compare to bagging and \n",
    "#pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of BaggingClassifier inbuilt class but we choose Algo. DecisionTreeClassifier() means\n",
    "#gini index means it is called random forest tree\n",
    "rft=BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=600,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82      1760\n",
      "           1       0.81      0.77      0.79      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.80      0.80      3349\n",
      "weighted avg       0.81      0.81      0.80      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1466  294]\n",
      " [ 359 1230]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=600, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call function\n",
    "create_model(rft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier : inbuilt class for randomforest , call RandomForestClassifier class means\n",
    "#always use decisiontreeclassifier means select imp features from dataset to predict the output\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of RandomForestClassifier class\n",
    "rf=RandomForestClassifier(n_estimators=10,max_features =10,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      1760\n",
      "           1       0.82      0.83      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1468  292]\n",
      " [ 277 1312]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "rf=create_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Stacking : -  This is Ensembling technique  .\n",
    "#we install a inbuilt package mlxtend for stacking : - only first time \n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call mlxtend package : StackingClassifier inbuilt class\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "#create object of DecisionTreeClassifier with gini index\n",
    "dt1=DecisionTreeClassifier() #befault gini index\n",
    "#create object of DecisionTreeClassifier with entropy\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model list \n",
    "model_list=[lr,dt1,dt2]\n",
    "#4th class : it is meta classifier : LogisticRegression  , create object  of meta classifier class\n",
    "meta=LogisticRegression()  #it is used for meta classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of StackingClassifier class\n",
    "sc=StackingClassifier(classifiers=model_list,meta_classifier=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1760\n",
      "           1       0.80      0.81      0.80      1589\n",
      "\n",
      "    accuracy                           0.81      3349\n",
      "   macro avg       0.81      0.81      0.81      3349\n",
      "weighted avg       0.81      0.81      0.81      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1441  319]\n",
      " [ 305 1284]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Now , we train and test the model and generate classification report and confusion matrix \n",
    "#then call function\n",
    "sc=create_model(sc)\n",
    "#best recall in random forest =0.83 in bank.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Boosting Technique : -\n",
    "#1. ADA Boost : Adaptor boosting \n",
    "#call class\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of AdaBoostClassifier class \n",
    "ada=AdaBoostClassifier(n_estimators=100) #passing arguments n_estimators means no. of iteration\n",
    "#value of this parameter can be <=100 not more than 100 for any dataset\n",
    "#not mension algorithm name because understood : decision tree ,its create a decision stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84      1760\n",
      "           1       0.83      0.80      0.82      1589\n",
      "\n",
      "    accuracy                           0.83      3349\n",
      "   macro avg       0.83      0.83      0.83      3349\n",
      "weighted avg       0.83      0.83      0.83      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1505  255]\n",
      " [ 317 1272]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "ada=create_model(ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. gradient Boost technuique : second tech. of Boosting Ensembling technique \n",
    "# GB  : - its create a fully grown tree.this algorithm is focus on short comings \n",
    "#short comings means error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call inbuilt class GradientBoostingClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of GradientBoostingClassifier  class\n",
    "gbc=GradientBoostingClassifier(n_estimators=100) #here n_estimators can be <=100 \n",
    "#here n_estimators is inbuilt parameter for iteration \n",
    "#GradientBoostingClassifier use always decision tree so not mension alogorithm name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84      1760\n",
      "           1       0.81      0.86      0.83      1589\n",
      "\n",
      "    accuracy                           0.84      3349\n",
      "   macro avg       0.84      0.84      0.84      3349\n",
      "weighted avg       0.84      0.84      0.84      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1436  324]\n",
      " [ 219 1370]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here recall is very good =0.86 as compare other ensembling tech. in ths dataset bank.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. It takes less memoryspace means optimising disk space . \\n   2. Faster process means processing is very fast\\n   3. It is very useful to handle huge data\\n   4. its handle overfitting situation automatic means to overcome the overfitting\\n   5. Its handle outlier automatic\\n   6. it use all \\ntechnology means to use multithreading.\\n   7. in this algo. , inbuilt capability to handle overfitting and outlier\\n   8. parellel learning'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Extreme Gradient Boosting(XGB) : - this is a gradient boost but this is better version of gradient\n",
    "#boost. XGB is similar work as GB. \n",
    "#Advantages of Extreme Gradient Boosting over Gradient Boosting : -\n",
    "'''1. It takes less memoryspace means optimising disk space . \n",
    "   2. Faster process means processing is very fast\n",
    "   3. It is very useful to handle huge data\n",
    "   4. its handle overfitting situation automatic means to overcome the overfitting\n",
    "   5. Its handle outlier automatic\n",
    "   6. it use all \n",
    "technology means to use multithreading.\n",
    "   7. in this algo. , inbuilt capability to handle overfitting and outlier\n",
    "   8. parellel learning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we instal the package first for XGB : - because it is not define in sklearn package\n",
    "#then first install package xgboost  only first time\n",
    "\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#call inbuilt class XGBClassifier which define inbuilt package xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of XGBClassifier class\n",
    "xg=XGBClassifier(n_estimators=25,reg_alpha=1) #reg_alpha inbuilt parameter , we pass value 1 means\n",
    "#to handle automatic overfitting and outlier situation means to overcome the overfitting\n",
    "#1 means true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:48:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1760\n",
      "           1       0.82      0.88      0.85      1589\n",
      "\n",
      "    accuracy                           0.85      3349\n",
      "   macro avg       0.85      0.85      0.85      3349\n",
      "weighted avg       0.85      0.85      0.85      3349\n",
      "\n",
      "Confusion Matrix \n",
      "[[1449  311]\n",
      " [ 197 1392]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "xg=create_model(xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
